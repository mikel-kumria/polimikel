{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTING SCRIPT\n",
    "This script:\n",
    "1. Loads the final quantized model from a saved checkpoint.\n",
    "2. Iterates over the test dataset folders, loads each CSV file individually (large data), feeds it into the model, and reports metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from Server_DataLoader import CustomSNNTestDataset, CLASSES\n",
    "import numpy as np\n",
    "\n",
    "test_dir = 'data/PROCESSED_YES_COCHLEA/CUT/TEST'\n",
    "model_path = 'logs/Mikel_LIF_quant_5bit/final_quantized_model_epoch1.pt'  # Example path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FakeQuantize5bit(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.levels = 32\n",
    "        self.w_min = 0.001\n",
    "        self.w_max = 1.0\n",
    "\n",
    "    def forward(self, input):\n",
    "\n",
    "        input_clamped = torch.clamp(input, self.w_min, self.w_max)\n",
    "        scale = (self.w_max - self.w_min) / (self.levels - 1)\n",
    "        quant_indices = torch.round((input_clamped - self.w_min) / scale)\n",
    "        quant_w = quant_indices * scale + self.w_min \n",
    "\n",
    "        return quant_w\n",
    "\n",
    "class QuantLinear(torch.nn.Linear):\n",
    "    def __init__(self, in_features, out_features, bias=False):\n",
    "        super().__init__(in_features, out_features, bias=bias)\n",
    "        self.fake_quant = FakeQuantize5bit()\n",
    "\n",
    "    def forward(self, input):\n",
    "        quant_weight = self.fake_quant(self.weight)\n",
    "        return torch.nn.functional.linear(input, quant_weight, self.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define SNNQUT structure (same as training code)\n",
    "# Make sure it matches exactly the trained model structure\n",
    "from snntorch import surrogate\n",
    "import snntorch as snn\n",
    "\n",
    "class SNNQUT(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, \n",
    "                 beta_hidden_1, beta_hidden_2, beta_hidden_3, beta_output, \n",
    "                 hidden_reset_mechanism, output_reset_mechanism, \n",
    "                 hidden_threshold, output_threshold, fast_sigmoid_slope):\n",
    "        super().__init__()\n",
    "        self.fc1 = QuantLinear(input_size, hidden_size, bias=False)\n",
    "        self.lif1 = snn.Leaky(beta=beta_hidden_1, reset_mechanism=hidden_reset_mechanism,\n",
    "                              threshold=hidden_threshold, \n",
    "                              spike_grad=surrogate.fast_sigmoid(slope=fast_sigmoid_slope))\n",
    "\n",
    "        self.fc2 = QuantLinear(hidden_size, hidden_size, bias=False)\n",
    "        self.lif2 = snn.Leaky(beta=beta_hidden_2, reset_mechanism=hidden_reset_mechanism,\n",
    "                              threshold=hidden_threshold, \n",
    "                              spike_grad=surrogate.fast_sigmoid(slope=fast_sigmoid_slope))\n",
    "\n",
    "        self.fc3 = QuantLinear(hidden_size, hidden_size, bias=False)\n",
    "        self.lif3 = snn.Leaky(beta=beta_hidden_3, reset_mechanism=hidden_reset_mechanism,\n",
    "                              threshold=hidden_threshold, \n",
    "                              spike_grad=surrogate.fast_sigmoid(slope=fast_sigmoid_slope))\n",
    "\n",
    "        self.fc4 = QuantLinear(hidden_size, output_size, bias=False)\n",
    "        self.lif4 = snn.Leaky(beta=beta_output, reset_mechanism=output_reset_mechanism,\n",
    "                              threshold=output_threshold)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.float()\n",
    "        batch_size, time_steps, _ = x.shape\n",
    "        device = x.device\n",
    "\n",
    "        mem1 = torch.zeros(batch_size, self.fc1.out_features, device=device)\n",
    "        mem2 = torch.zeros(batch_size, self.fc2.out_features, device=device)\n",
    "        mem3 = torch.zeros(batch_size, self.fc3.out_features, device=device)\n",
    "        mem4 = torch.zeros(batch_size, self.fc4.out_features, device=device)\n",
    "\n",
    "        spk4_rec = []\n",
    "        mem4_rec = []\n",
    "\n",
    "        for step in range(time_steps):\n",
    "            cur1 = self.fc1(x[:, step, :])\n",
    "            spk1, mem1 = self.lif1(cur1, mem1)\n",
    "            cur2 = self.fc2(spk1)\n",
    "            spk2, mem2 = self.lif2(cur2, mem2)\n",
    "            cur3 = self.fc3(spk2)\n",
    "            spk3, mem3 = self.lif3(cur3, mem3)\n",
    "            cur4 = self.fc4(spk3)\n",
    "            spk4, mem4 = self.lif4(cur4, mem4)\n",
    "\n",
    "            spk4_rec.append(spk4)\n",
    "            mem4_rec.append(mem4)\n",
    "\n",
    "        return torch.stack(spk4_rec, dim=0), torch.stack(mem4_rec, dim=0)\n",
    "\n",
    "def load_model(model_path, input_size=16, hidden_size=24, output_size=4,\n",
    "               beta_hidden_1=None, beta_hidden_2=None, beta_hidden_3=None, beta_output=None,\n",
    "               hidden_reset_mechanism='subtract', output_reset_mechanism='none',\n",
    "               hidden_threshold=1, output_threshold=1e7, fast_sigmoid_slope=10):\n",
    "    # Use the same beta values as training script\n",
    "    def create_power_vector(n, size):\n",
    "        powers = [2 ** i for i in range(1, n + 1)]\n",
    "        repeat_count = size // n\n",
    "        power_vector = np.repeat(powers, repeat_count)\n",
    "        return power_vector\n",
    "\n",
    "    size = hidden_size\n",
    "    tau_hidden_1 = create_power_vector(n=2, size=size)\n",
    "    tau_hidden_2 = create_power_vector(n=4, size=size)\n",
    "    tau_hidden_3 = create_power_vector(n=8, size=size)\n",
    "\n",
    "    delta_t = 1\n",
    "    beta_hidden_1 = torch.exp(-torch.tensor(delta_t) / torch.tensor(tau_hidden_1, dtype=torch.float32))\n",
    "    beta_hidden_2 = torch.exp(-torch.tensor(delta_t) / torch.tensor(tau_hidden_2, dtype=torch.float32))\n",
    "    beta_hidden_3 = torch.exp(-torch.tensor(delta_t) / torch.tensor(tau_hidden_3, dtype=torch.float32))\n",
    "\n",
    "    tau_output = np.repeat(10, output_size)\n",
    "    beta_output = torch.exp(-torch.tensor(delta_t) / torch.tensor(tau_output, dtype=torch.float32))\n",
    "\n",
    "    model = SNNQUT(\n",
    "        input_size=input_size,\n",
    "        hidden_size=hidden_size,\n",
    "        output_size=output_size,\n",
    "        beta_hidden_1=beta_hidden_1,\n",
    "        beta_hidden_2=beta_hidden_2,\n",
    "        beta_hidden_3=beta_hidden_3,\n",
    "        beta_output=beta_output,\n",
    "        hidden_reset_mechanism=hidden_reset_mechanism,\n",
    "        output_reset_mechanism=output_reset_mechanism,\n",
    "        hidden_threshold=hidden_threshold,\n",
    "        output_threshold=output_threshold,\n",
    "        fast_sigmoid_slope=fast_sigmoid_slope,\n",
    "    )\n",
    "\n",
    "    state_dict = torch.load(model_path, map_location='cpu')\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model = load_model(model_path)\n",
    "    test_dataset = CustomSNNTestDataset(test_dir)\n",
    "\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    # We just run inference on each test folder\n",
    "    for i in range(len(test_dataset)):\n",
    "        folder_path, label = test_dataset[i]\n",
    "        csv_files = glob.glob(os.path.join(folder_path, '*.csv'))\n",
    "        # Load and process each CSV file (heavy)\n",
    "        for csv_file in csv_files:\n",
    "            data = np.loadtxt(csv_file, delimiter=',', dtype=np.float32)\n",
    "            # data shape: (60000, 16)\n",
    "            inputs = torch.tensor(data).unsqueeze(0) # shape (1, time_steps, input_dim)\n",
    "            with torch.no_grad():\n",
    "                spk4, mem4 = model(inputs)\n",
    "                final_out = mem4.sum(0)  # shape (batch, output_size)\n",
    "                _, predicted = final_out.max(-1)\n",
    "                _, targets = label.unsqueeze(0).max(-1)\n",
    "                correct = predicted.eq(targets).sum().item()\n",
    "                total_correct += correct\n",
    "                total_samples += targets.numel()\n",
    "\n",
    "    accuracy = (total_correct / total_samples)*100 if total_samples > 0 else 0.0\n",
    "    print(f\"Test Accuracy: {accuracy:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
